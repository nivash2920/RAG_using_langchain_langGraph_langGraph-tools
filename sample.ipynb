{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090f227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Desktop\\rough\\jgenai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc051236",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader('NIVASH__R.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a321f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68235a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='NIVASH R \\n    Coimbatore |         nivash2920@gmail.com | ✆ +91 94452 91158 |  nivash-r \\n \\nSUMMARY \\nInnovative Software Engineer with a strong foundation in designing, optimizing, and automating data -driven workflows. \\nRecognized for bridging data engineering with emerging AI practices to create intelligent, end-to-end systems that drive \\nbusiness value. Skilled at transforming complex data into meaningful insights and ensuring that technical solutions align \\nwith organizational goals in a fast-evolving technological landscape. Committed to delivering scalable and reliable \\nsolutions that drive efficiency, strengthen workflows, and keep pace with rapidly changing business and technology \\nenvironments. \\n \\nSKILLS \\nCategory Technologies / Tools / Skills \\nProgramming Languages Python \\nCloud Platforms Google Cloud Platform (GCP), Amazon Web Services (AWS) \\nData Engineering & Processing Data Engineering, ETL Development, SQL, PySpark, Workflow Automation, \\nCloud Data Pipelines \\nAI, ML & Generative AI Generative AI + Data Engineering (Hybrid), LLMs, LangChain, RAG Pipelines, \\nPrompt Engineering, AI Agents, Machine Learning (ML) & Deep Learning (DL) \\nFundamentals \\nData Visualization & Analytics Power BI, Tableau, Looker, Exploratory Data Analysis (EDA) \\nVersion Control & Collaboration Git, Workflow Management, Automation in Cloud Environments \\n \\nEXPERIENCE \\nSoftware Engineer \\nTEKsystems Global Services – Bangalore             September 2022 – Present \\n• Built a complete ETL pipeline for large datasets, transforming and structuring data and delivering interactive \\ndashboards to provide actionable insights. \\n• Structured and optimized datasets for a recommendation engine, enabling real-time, personalized suggestions \\nand ensuring data consistency for analytical use. \\n• Automated cloud resource management, including cleanup of aged resources and enforcing access governance, \\nimproving efficiency and cost control. \\n• Refined AI-driven recommendations by iteratively improving prompt strategies, enhancing accuracy and user \\nexperience. \\n• Improved internal chatbot performance by analysing gaps, creating new intents, and reducing fallback responses, \\nboosting operational efficiency and user satisfaction. \\n \\nSoftware Engineer (Contingent) \\nMeta – Bangalore                                                            November 2023 – July 2025 \\n• Improved data quality and annotation workflows for Generative AI projects by developing Python scripts and SQL \\nqueries to clean, transform, and structure large datasets for LLM training.'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='• Integrated large language models into Python workflows to systematically evaluate prompt effectiveness, capture \\nmodel responses, and analyze results for optimization. \\n• Created interactive dashboards to visualize annotation quality and model outputs, enabling teams to monitor \\nperformance and refine training datasets. \\n• Increased efficiency and accuracy in AI model training by leveraging data engineering skills for Generative AI \\nworkflows. \\n \\nCERTIFICATIONS \\n• Google Associate Cloud Engineer - GCP \\n• Full Stack Developer - Simplilearn \\n• Python Programming - Udemy \\n• Python Coding - HackerRank \\n• Generative AI - Databricks \\n• AWS Certified Data Engineer - AWS \\n \\nEDUCATION \\nB.Tech – Information Technology                  2018 – 2022 | GPA: 8.2 Kongu Engineering College – Erode \\n \\nPROJECTS \\nProject Description \\nLLM Data Pipeline & Annotation Analytics \\n(Meta) \\nDeveloped and optimized data pipelines and annotation workflows for \\nLLM training, improving data quality, model performance, and analytics \\nvisibility. \\nGoogle Cloud Platform (GCP) Automation Automated cloud resource management and access governance, \\nreducing costs, improving efficiency, and ensuring compliance across \\nthe platform. \\nETL Data Pipeline in Google Cloud Built a scalable ETL pipeline to process, transform, and analyze large \\noperational datasets, providing actionable insights through interactive \\ndashboards. \\nRAG-Based Chatbot using Large Language \\nModels and Vector Databases (Self-Driven \\nProject) \\nDesigned and deployed an AI-powered chatbot using a RAG approach \\nto deliver accurate, document-based answers through an end-to-end \\nGenerative AI workflow. \\nGCP Recommendation AI (POC Project) Structured and optimized large datasets to enable real-time, \\npersonalized product recommendations with consistent and reliable \\nanalytical processing. \\nVertex AI – Prompt Engineering & \\nRecommendation Updates (POC Project) \\nRefined AI-generated recommendations using iterative prompt \\nstrategies, enhancing accuracy and real-time adaptability for users. \\nDialogue Flow & Intent Optimization – \\nInternal CX Project (POC Project) \\nImproved chatbot performance by analyzing and creating intents, \\nreducing fallback responses, and enhancing query accuracy.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef5935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473c652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter= RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297ef18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk=splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7526965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='NIVASH R \\n    Coimbatore |         nivash2920@gmail.com | ✆ +91 94452 91158 |  nivash-r \\n \\nSUMMARY \\nInnovative Software Engineer with a strong foundation in designing, optimizing, and automating data -driven workflows. \\nRecognized for bridging data engineering with emerging AI practices to create intelligent, end-to-end systems that drive \\nbusiness value. Skilled at transforming complex data into meaningful insights and ensuring that technical solutions align'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='with organizational goals in a fast-evolving technological landscape. Committed to delivering scalable and reliable \\nsolutions that drive efficiency, strengthen workflows, and keep pace with rapidly changing business and technology \\nenvironments. \\n \\nSKILLS \\nCategory Technologies / Tools / Skills \\nProgramming Languages Python \\nCloud Platforms Google Cloud Platform (GCP), Amazon Web Services (AWS)'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Cloud Platforms Google Cloud Platform (GCP), Amazon Web Services (AWS) \\nData Engineering & Processing Data Engineering, ETL Development, SQL, PySpark, Workflow Automation, \\nCloud Data Pipelines \\nAI, ML & Generative AI Generative AI + Data Engineering (Hybrid), LLMs, LangChain, RAG Pipelines, \\nPrompt Engineering, AI Agents, Machine Learning (ML) & Deep Learning (DL) \\nFundamentals \\nData Visualization & Analytics Power BI, Tableau, Looker, Exploratory Data Analysis (EDA)'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Data Visualization & Analytics Power BI, Tableau, Looker, Exploratory Data Analysis (EDA) \\nVersion Control & Collaboration Git, Workflow Management, Automation in Cloud Environments \\n \\nEXPERIENCE \\nSoftware Engineer \\nTEKsystems Global Services – Bangalore             September 2022 – Present \\n• Built a complete ETL pipeline for large datasets, transforming and structuring data and delivering interactive \\ndashboards to provide actionable insights.'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='dashboards to provide actionable insights. \\n• Structured and optimized datasets for a recommendation engine, enabling real-time, personalized suggestions \\nand ensuring data consistency for analytical use. \\n• Automated cloud resource management, including cleanup of aged resources and enforcing access governance, \\nimproving efficiency and cost control. \\n• Refined AI-driven recommendations by iteratively improving prompt strategies, enhancing accuracy and user \\nexperience.'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='experience. \\n• Improved internal chatbot performance by analysing gaps, creating new intents, and reducing fallback responses, \\nboosting operational efficiency and user satisfaction. \\n \\nSoftware Engineer (Contingent) \\nMeta – Bangalore                                                            November 2023 – July 2025 \\n• Improved data quality and annotation workflows for Generative AI projects by developing Python scripts and SQL'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='queries to clean, transform, and structure large datasets for LLM training.'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='• Integrated large language models into Python workflows to systematically evaluate prompt effectiveness, capture \\nmodel responses, and analyze results for optimization. \\n• Created interactive dashboards to visualize annotation quality and model outputs, enabling teams to monitor \\nperformance and refine training datasets. \\n• Increased efficiency and accuracy in AI model training by leveraging data engineering skills for Generative AI \\nworkflows. \\n \\nCERTIFICATIONS'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='workflows. \\n \\nCERTIFICATIONS \\n• Google Associate Cloud Engineer - GCP \\n• Full Stack Developer - Simplilearn \\n• Python Programming - Udemy \\n• Python Coding - HackerRank \\n• Generative AI - Databricks \\n• AWS Certified Data Engineer - AWS \\n \\nEDUCATION \\nB.Tech – Information Technology                  2018 – 2022 | GPA: 8.2 Kongu Engineering College – Erode \\n \\nPROJECTS \\nProject Description \\nLLM Data Pipeline & Annotation Analytics \\n(Meta)'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='PROJECTS \\nProject Description \\nLLM Data Pipeline & Annotation Analytics \\n(Meta) \\nDeveloped and optimized data pipelines and annotation workflows for \\nLLM training, improving data quality, model performance, and analytics \\nvisibility. \\nGoogle Cloud Platform (GCP) Automation Automated cloud resource management and access governance, \\nreducing costs, improving efficiency, and ensuring compliance across \\nthe platform.'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='reducing costs, improving efficiency, and ensuring compliance across \\nthe platform. \\nETL Data Pipeline in Google Cloud Built a scalable ETL pipeline to process, transform, and analyze large \\noperational datasets, providing actionable insights through interactive \\ndashboards. \\nRAG-Based Chatbot using Large Language \\nModels and Vector Databases (Self-Driven \\nProject) \\nDesigned and deployed an AI-powered chatbot using a RAG approach'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Project) \\nDesigned and deployed an AI-powered chatbot using a RAG approach \\nto deliver accurate, document-based answers through an end-to-end \\nGenerative AI workflow. \\nGCP Recommendation AI (POC Project) Structured and optimized large datasets to enable real-time, \\npersonalized product recommendations with consistent and reliable \\nanalytical processing. \\nVertex AI – Prompt Engineering & \\nRecommendation Updates (POC Project) \\nRefined AI-generated recommendations using iterative prompt'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'NIVASH__R.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Recommendation Updates (POC Project) \\nRefined AI-generated recommendations using iterative prompt \\nstrategies, enhancing accuracy and real-time adaptability for users. \\nDialogue Flow & Intent Optimization – \\nInternal CX Project (POC Project) \\nImproved chatbot performance by analyzing and creating intents, \\nreducing fallback responses, and enhancing query accuracy.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c2ffe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6693649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16368\\3409896792.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f9593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# test_vec= embeddings.embed_query('list all the skills')\n",
    "# print(len(test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac856ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89ee845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=FAISS.from_documents(chunk,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71ac014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 13 vectors\n"
     ]
    }
   ],
   "source": [
    "print(\"FAISS index created with\", db.index.ntotal, \"vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eeeea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee45166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16368\\2984537256.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c8b5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07b16305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nUse the following context to answer the question:\\n{context}\\nQuestion: {question}\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template=  \"\"\"\n",
    "Use the following context to answer the question:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt=ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05bea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Querying the RAG System ===\n",
      "\n",
      "Question: list all the certifications?\n",
      "Answer: The human has the following certifications:\n",
      "\n",
      "1. Google Associate Cloud Engineer - GCP\n",
      "2. Full Stack Developer - Simplilearn\n",
      "3. Python Programming - Udemy\n",
      "4. Python Coding - HackerRank\n",
      "5. Generative AI - Databricks\n",
      "6. AWS Certified Data Engineer - AWS\n",
      "\n",
      "Question: list all the poc worked on?\n",
      "Answer: Based on the provided context, here is the list of POC (Proof-of-Concept) projects mentioned:\n",
      "\n",
      "1. Recommendation Updates (POC Project) - Refined AI-generated recommendations using iterative prompt strategies.\n",
      "2. Dialogue Flow & Intent Optimization – Internal CX Project (POC Project) - Improved chatbot performance by analyzing and creating intents.\n",
      "\n",
      "Note that there are also mentions of other projects, but they seem to be part of the individual's education or certifications rather than POC projects specifically.\n",
      "\n",
      "Question: Can this person work as junior genai developer?\n",
      "Answer: Based on the provided context, it seems likely that Nivash R can work as a Junior Genai Developer. Here's why:\n",
      "\n",
      "1. Experience with Generative AI projects: Nivash has experience in improving data quality and annotation workflows for Generative AI projects, which suggests they have hands-on experience working with this technology.\n",
      "2. Programming skills: They have developed Python scripts and SQL, which are essential programming languages for many AI and machine learning applications.\n",
      "3. Data engineering skills: As a software engineer, Nivash has a strong foundation in designing, optimizing, and automating data-driven workflows, which is relevant to working with Generative AI.\n",
      "4. Ability to learn and adapt: The fact that they can analyze gaps in chatbot performance and improve operational efficiency suggests they have the ability to identify areas for improvement and implement changes.\n",
      "\n",
      "However, it's worth noting that the title \"Software Engineer\" might imply a higher level of seniority or experience than what is typically required for a Junior Genai Developer role. But based on their skills and experience, it seems like Nivash R has the potential to excel in this role with some guidance and support.\n",
      "\n",
      "To confirm, more information about the specific requirements and responsibilities of the Junior Genai Developer position would be needed.\n",
      "\n",
      "Vector store saved to 'faiss_index_hf'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 8. Create the RAG chain using LCEL\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | (lambda docs: \"\\n\\n\".join(doc.page_content for doc in docs)), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "#✅ Simple analogy: You asked “BMW AI vision” → retriever finds 3 chunks → lambda joins them into a single paragraph for the LLM.\n",
    "# This becomes input | to this\n",
    "\n",
    "# 9. Query the RAG system\n",
    "questions = [\n",
    "    \"list all the certifications?\",\n",
    "    \"list all the poc worked on?\",\n",
    "    \"Can this person work as junior genai developer?\"\n",
    "]\n",
    "\n",
    "print(\"\\n=== Querying the RAG System ===\")\n",
    "for question in questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    answer = rag_chain.invoke(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "# 10. Save the vector store for future use\n",
    "#vectorstore.save_local(\"faiss_index_hf\")\n",
    "print(\"\\nVector store saved to 'faiss_index_hf'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009aa9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jgenai (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
