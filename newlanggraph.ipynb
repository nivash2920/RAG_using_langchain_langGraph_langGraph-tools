{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph RAG Walkthrough\n",
        "\n",
        "This notebook recreates the `rag.ipynb` pipeline using LangGraph. We still load PDFs, chunk text, build FAISS embeddings, and call the Ollama LLM, but the orchestration now goes through a declarative graph instead of LangChain's runnable pipeline. Markdown callouts highlight what is new and why.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os  # Core file-system utilities used to enumerate PDFs.\n",
        "from typing import TypedDict  # Provides structured state typing for LangGraph nodes.\n",
        "\n",
        "from IPython.display import display, Image  # `Image` wraps byte buffers; `display` shows them inline.\n",
        "from langchain_community.document_loaders import PyPDFLoader  # Reads PDF pages into LangChain-compatible docs.\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter  # Splits documents while respecting overlaps.\n",
        "from langchain_huggingface import HuggingFaceEmbeddings  # Access to sentence-transformers via LangChain interface.\n",
        "from langchain_community.vectorstores import FAISS  # Lightweight FAISS wrapper to persist embeddings in-memory.\n",
        "from langchain_ollama import OllamaLLM  # LangChain driver that talks to the local Ollama runtime.\n",
        "from langchain_core.prompts import ChatPromptTemplate  # Lets us template user + context inputs.\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END  # Core LangGraph API to wire nodes + define entry/exit handles.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Document Loading\n",
        "We keep the same PDF loader setup from `rag.ipynb`. The LangGraph changes come later; the ingestion code is identical so we can compare behaviors apples-to-apples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DOCS_FOLDER = r\"C:\\\\Users\\\\Asus\\\\Documents\\\\all_doc\"  # Root directory containing project PDFs.\n",
        "\n",
        "documents = []  # Acts as our in-memory corpus before chunking.\n",
        "for file in os.listdir(DOCS_FOLDER):  # Iterate over every file in the target directory.\n",
        "    if file.lower().endswith(\".pdf\"):  # Guard clause ensures we only ingest PDFs.\n",
        "        loader = PyPDFLoader(os.path.join(DOCS_FOLDER, file))  # Loader keeps per-page metadata LangChain expects.\n",
        "        documents.extend(loader.load())  # Extend so each page Document object is appended individually.\n",
        "\n",
        "len(documents)  # Quick sanity check so we know how many page-level documents were collected.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chunking and Embeddings\n",
        "No LangGraph changes yet—this remains pure LangChain utility code so our FAISS index matches the original notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split into 15 chunks\n",
            "Vector store holds 15 embeddings\n"
          ]
        }
      ],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,  # Chunk size controls token budget; 500 chars mirrors the LangChain baseline.\n",
        "    chunk_overlap=10,  # Small overlap keeps sentence continuity w/out ballooning chunk count.\n",
        ")\n",
        "chunks = splitter.split_documents(documents)  # Materializes list[Document] chunks annotated w/ metadata.\n",
        "print(f\"Split into {len(chunks)} chunks\")  # Diagnostic print => ensures ingestion roughly matches expectation.\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"  # Same MiniLM model used previously for parity.\n",
        ")\n",
        "vector_store = FAISS.from_documents(chunks, embedding)  # Indexes embeddings into in-memory FAISS.\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_kwargs={\"k\": 10}  # `k`=10 keeps recall comparable to the LangChain runnable example.\n",
        ")\n",
        "print(f\"Vector store holds {vector_store.index.ntotal} embeddings\")  # Confirms FAISS rows == chunk count.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## From LangChain Runnables to LangGraph\n",
        "The original notebook piped components with `RunnablePassthrough`. LangGraph instead models the flow as a graph of **stateful nodes**. We describe the state schema and wire each node explicitly—this makes branching or streaming paths easier later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RAGState(TypedDict, total=False):\n",
        "    \"\"\"Structure shared between LangGraph nodes. `total=False` keeps each key optional.\"\"\"\n",
        "\n",
        "    question: str  # User input captured at START.\n",
        "    context: str  # Retriever output flattened into newline-delimited text.\n",
        "    prompt: str  # Rendered template ready for the LLM.\n",
        "    answer: str  # Final LLM response string.\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Give response only from the below details\n",
        "{context}\n",
        "question : {question}\n",
        "\"\"\"  # Same template text from the LangChain notebook for true apples-to-apples comparison.\n",
        ")\n",
        "\n",
        "llm = OllamaLLM(\n",
        "    model=\"llama3.2\"  # Parameter selects the local Ollama model tag; change here to swap models globally.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node Responsibilities\n",
        "Each LangGraph node is a plain Python function. Comments inline explain the **why/how** for every argument and return value so you can trace state mutations step-by-step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_node(state: RAGState) -> RAGState:\n",
        "    \"\"\"Queries FAISS via LangChain's retriever wrapper to gather context.\"\"\"\n",
        "\n",
        "    docs = retriever.invoke(state[\"question\"])  # `invoke` handles sync retrieval for a single query string.\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)  # Flatten Document list into readable paragraphs.\n",
        "    return {\"question\": state[\"question\"], \"context\": context}  # Pass through question so downstream nodes keep it.\n",
        "\n",
        "\n",
        "def prompt_node(state: RAGState) -> RAGState:\n",
        "    \"\"\"Fills the chat template using the state dictionary.\"\"\"\n",
        "\n",
        "    prompt = prompt_template.format(**state)  # `**state` auto-maps keys to template placeholders.\n",
        "    return {**state, \"prompt\": prompt}  # Merge previous state while injecting the rendered prompt string.\n",
        "\n",
        "\n",
        "def llm_node(state: RAGState) -> RAGState:\n",
        "    \"\"\"Calls the local Ollama model and stores its textual answer.\"\"\"\n",
        "\n",
        "    answer = llm.invoke(state[\"prompt\"])  # `invoke` blocks until the model finishes streaming tokens.\n",
        "    return {**state, \"answer\": answer}  # Persist everything so END has both context + answer for inspection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Building the LangGraph\n",
        "Unlike LangChain's implicit pipe, we now define nodes + explicit edges. This exposes the exact flow, makes it trivial to add inspection hooks, and enables conditional edges later if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph_builder = StateGraph(RAGState)  # `StateGraph` enforces that each node reads/writes the RAGState schema.\n",
        "\n",
        "# --- Node registration -------------------------------------------------------------------------------------------\n",
        "graph_builder.add_node(\"retrieve\", retrieve_node)  # First node pulls knowledge from FAISS.\n",
        "graph_builder.add_node(\"prompt\", prompt_node)  # Second node formats the prompt string.\n",
        "graph_builder.add_node(\"llm\", llm_node)  # Final node calls the LLM and stores the answer.\n",
        "\n",
        "# --- Edge wiring --------------------------------------------------------------------------------------------------\n",
        "graph_builder.add_edge(START, \"retrieve\")  # Entry point automatically injects the initial question payload.\n",
        "graph_builder.add_edge(\"retrieve\", \"prompt\")  # Flow retrieved context into prompt rendering.\n",
        "graph_builder.add_edge(\"prompt\", \"llm\")  # Ensure the formatted prompt feeds the LLM call.\n",
        "graph_builder.add_edge(\"llm\", END)  # EXIT node exposes the final state back to caller.\n",
        "\n",
        "graph = graph_builder.compile()  # `compile` freezes the topology so we can call invoke/astream later.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running Questions Through the Graph\n",
        "Execution now goes through `graph.invoke`, which keeps the intermediate state accessible for debugging (you can inspect `context` or `prompt` after each node if desired).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt : list the projects done in meta and teksystems\n",
            "Response : Here are the projects done:\n",
            "\n",
            "1. LLM Data Pipeline & Annotation Analytics (Meta) - November 2023 – July 2025:\n",
            "   • Improved data quality and annotation workflows for Generative AI projects by developing Python scripts and SQL queries.\n",
            "   • Assisted in process improvement initiatives by analyzing transaction data trends and identifying bottlenecks.\n",
            "\n",
            "2. Recommendation Updates (POC Project) at Meta: \n",
            "   Refined AI-generated recommendations using iterative prompt strategies, enhancing accuracy and real-time adaptability for users.\n",
            "\n",
            "3. Dialogue Flow & Intent Optimization – Internal CX Project at Meta (POC Project):\n",
            "   Improved chatbot performance by analyzing and creating intents, reducing fallback responses, and enhancing query accuracy.\n",
            "\n",
            "Prompt : list the skillset of nivash and sahana\n",
            "Response : Here are the skills listed for both Nivash and Sahana:\n",
            "\n",
            "**Nivash:**\n",
            "\n",
            "1. Programming Languages:\n",
            "   - Python\n",
            "2. Cloud Platforms:\n",
            "   - Google Cloud Platform (GCP)\n",
            "   - Amazon Web Services (AWS)\n",
            "3. Technical Skills:\n",
            "   - DBMS\n",
            "   - SQL\n",
            "   - Data Analysis & Visualization\n",
            "   - Technical Troubleshooting & Issue Resolution\n",
            "4. Business & Domain Skills:\n",
            "   - Banking Operations & Compliance\n",
            "   - Customer Data Management & Risk Analysis\n",
            "   - Business Process Improvement\n",
            "5. Soft Skills:\n",
            "   - Analytical Thinking & Problem Solving\n",
            "   - Strong Communication & Presentation\n",
            "   - Team Collaboration and Management\n",
            "\n",
            "**Sahana:**\n",
            "\n",
            "1. Programming Languages:\n",
            "   - Python\n",
            "2. Cloud Platforms:\n",
            "   - Google Associate Cloud Engineer (GCP)\n",
            "3. Technical Skills:\n",
            "   - Data Engineering & Processing\n",
            "     - ETL Development\n",
            "     - SQL\n",
            "     - PySpark\n",
            "     - Workflow Automation\n",
            "     - Cloud Data Pipelines\n",
            "   - AI, ML & Generative AI\n",
            "     - Generative AI + Data Engineering (Hybrid)\n",
            "     - LLMs\n",
            "     - LangChain\n",
            "     - RAG Pipelines\n",
            "     - Prompt Engineering\n",
            "     - AI Agents\n",
            "     - Machine Learning (ML) & Deep Learning (DL)\n",
            "   - Fundamentals:\n",
            "     - Data Visualization & Analytics\n",
            "       - Power BI\n",
            "       - Tableau\n",
            "       - Looker\n",
            "       - Exploratory Data Analysis (EDA)\n",
            "   - Version Control & Collaboration:\n",
            "     - Git\n",
            "     - Workflow Management\n",
            "     - Automation in Cloud Environments\n",
            "4. Business & Domain Skills:\n",
            "   - Not explicitly mentioned in the given details.\n",
            "5. Soft Skills:\n",
            "   - Strong communication and analytical abilities\n",
            "   - Adept at troubleshooting technical issues, updating knowledge bases\n",
            "\n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    \"list the projects done in meta and teksystems\",  # Same question from the LangChain baseline for parity.\n",
        "    \"list the skillset of nivash and sahana\",  # Second question exercises the same retrieval pathway.\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    result = graph.invoke({\"question\": question})  # `invoke` seeds the graph with the user's question.\n",
        "    print(f\"Prompt : {question}\")  # Echo input so notebook logs stay readable.\n",
        "    print(f\"Response : {result['answer']}\\n\")  # Answers live under the `answer` key in the final state dict.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the Workflow\n",
        "LangGraph gives a built-in graph object, so documenting the flow is trivial. This is the direct analog to the Mermaid export we tried earlier, but it comes straight from the compiled graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# mermaid_diagram = graph.get_graph().draw_mermaid()  # Mermaid text is great for version control diffs.\n",
        "# print(mermaid_diagram)\n",
        "\n",
        "# with open(\"langgraph_rag.mmd\", \"w\", encoding=\"utf-8\") as f:  # Persist textual diagram for docs.\n",
        "#     f.write(mermaid_diagram)\n",
        "\n",
        "mermaid_png = graph.get_graph().draw_mermaid_png()  # Binary PNG variant renders nicely inline.\n",
        "with open(\"langgraph_rag.png\", \"wb\") as f:  # Save so it can be embedded elsewhere (e.g., README).\n",
        "    f.write(mermaid_png)\n",
        "\n",
        "display(Image(mermaid_png))  # Show the actual graph picture right below the cell, as requested.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Differences vs LangChain Runnable Pipeline\n",
        "- **State visibility:** Every node returns the typed `RAGState`, so you can tap into intermediate data without rewiring the chain.\n",
        "- **Branching readiness:** Adding guardrails, retries, or evaluator branches becomes an edge change instead of rewriting the pipeline.\n",
        "- **Shared components:** Loaders, splitters, embeddings, and FAISS stay identical; LangGraph just replaces the orchestration layer.\n",
        "- **LLM execution:** We still call Ollama, but it now sits behind a named node (`llm`). This makes it easy to swap with a guard or reflection node later.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
