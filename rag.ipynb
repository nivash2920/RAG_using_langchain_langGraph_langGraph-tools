{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc313cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26765cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Asus\\\\Desktop\\\\all projects & learnings\\\\llm-rag-fastapi-study'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path=os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d55a2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=\"C:\\\\Users\\\\Asus\\\\Documents\\\\all_doc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1713e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13d7189c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'C:\\\\Users\\\\Asus\\\\Documents\\\\all_doc\\\\NIVASH__R.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='NIVASH R \\n    Coimbatore |         nivash2920@gmail.com | ✆ +91 94452 91158 |  nivash-r \\n \\nSUMMARY \\nInnovative Software Engineer with a strong foundation in designing, optimizing, and automating data -driven workflows. \\nRecognized for bridging data engineering with emerging AI practices to create intelligent, end-to-end systems that drive \\nbusiness value. Skilled at transforming complex data into meaningful insights and ensuring that technical solutions align \\nwith organizational goals in a fast-evolving technological landscape. Committed to delivering scalable and reliable \\nsolutions that drive efficiency, strengthen workflows, and keep pace with rapidly changing business and technology \\nenvironments. \\n \\nSKILLS \\nCategory Technologies / Tools / Skills \\nProgramming Languages Python \\nCloud Platforms Google Cloud Platform (GCP), Amazon Web Services (AWS) \\nData Engineering & Processing Data Engineering, ETL Development, SQL, PySpark, Workflow Automation, \\nCloud Data Pipelines \\nAI, ML & Generative AI Generative AI + Data Engineering (Hybrid), LLMs, LangChain, RAG Pipelines, \\nPrompt Engineering, AI Agents, Machine Learning (ML) & Deep Learning (DL) \\nFundamentals \\nData Visualization & Analytics Power BI, Tableau, Looker, Exploratory Data Analysis (EDA) \\nVersion Control & Collaboration Git, Workflow Management, Automation in Cloud Environments \\n \\nEXPERIENCE \\nSoftware Engineer \\nTEKsystems Global Services – Bangalore             September 2022 – Present \\n• Built a complete ETL pipeline for large datasets, transforming and structuring data and delivering interactive \\ndashboards to provide actionable insights. \\n• Structured and optimized datasets for a recommendation engine, enabling real-time, personalized suggestions \\nand ensuring data consistency for analytical use. \\n• Automated cloud resource management, including cleanup of aged resources and enforcing access governance, \\nimproving efficiency and cost control. \\n• Refined AI-driven recommendations by iteratively improving prompt strategies, enhancing accuracy and user \\nexperience. \\n• Improved internal chatbot performance by analysing gaps, creating new intents, and reducing fallback responses, \\nboosting operational efficiency and user satisfaction. \\n \\nSoftware Engineer (Contingent) \\nMeta – Bangalore                                                            November 2023 – July 2025 \\n• Improved data quality and annotation workflows for Generative AI projects by developing Python scripts and SQL \\nqueries to clean, transform, and structure large datasets for LLM training.'),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-09-30T18:26:34+05:30', 'author': 'R, Nivash', 'moddate': '2025-09-30T12:59:10+00:00', 'source': 'C:\\\\Users\\\\Asus\\\\Documents\\\\all_doc\\\\NIVASH__R.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='• Integrated large language models into Python workflows to systematically evaluate prompt effectiveness, capture \\nmodel responses, and analyze results for optimization. \\n• Created interactive dashboards to visualize annotation quality and model outputs, enabling teams to monitor \\nperformance and refine training datasets. \\n• Increased efficiency and accuracy in AI model training by leveraging data engineering skills for Generative AI \\nworkflows. \\n \\nCERTIFICATIONS \\n• Google Associate Cloud Engineer - GCP \\n• Full Stack Developer - Simplilearn \\n• Python Programming - Udemy \\n• Python Coding - HackerRank \\n• Generative AI - Databricks \\n• AWS Certified Data Engineer - AWS \\n \\nEDUCATION \\nB.Tech – Information Technology                  2018 – 2022 | GPA: 8.2 Kongu Engineering College – Erode \\n \\nPROJECTS \\nProject Description \\nLLM Data Pipeline & Annotation Analytics \\n(Meta) \\nDeveloped and optimized data pipelines and annotation workflows for \\nLLM training, improving data quality, model performance, and analytics \\nvisibility. \\nGoogle Cloud Platform (GCP) Automation Automated cloud resource management and access governance, \\nreducing costs, improving efficiency, and ensuring compliance across \\nthe platform. \\nETL Data Pipeline in Google Cloud Built a scalable ETL pipeline to process, transform, and analyze large \\noperational datasets, providing actionable insights through interactive \\ndashboards. \\nRAG-Based Chatbot using Large Language \\nModels and Vector Databases (Self-Driven \\nProject) \\nDesigned and deployed an AI-powered chatbot using a RAG approach \\nto deliver accurate, document-based answers through an end-to-end \\nGenerative AI workflow. \\nGCP Recommendation AI (POC Project) Structured and optimized large datasets to enable real-time, \\npersonalized product recommendations with consistent and reliable \\nanalytical processing. \\nVertex AI – Prompt Engineering & \\nRecommendation Updates (POC Project) \\nRefined AI-generated recommendations using iterative prompt \\nstrategies, enhancing accuracy and real-time adaptability for users. \\nDialogue Flow & Intent Optimization – \\nInternal CX Project (POC Project) \\nImproved chatbot performance by analyzing and creating intents, \\nreducing fallback responses, and enhancing query accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'FlowCV - https://flowcv.com', 'creationdate': '2025-09-26T19:51:35+00:00', 'moddate': '2025-09-26T19:51:35+00:00', 'keywords': 'FlowCV – Online Resume Builder – https://flowcv.com', 'source': 'C:\\\\Users\\\\Asus\\\\Documents\\\\all_doc\\\\Sahana.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Sahana Shankaran\\nsahanarakesh24@gmail.com 8438094957\\nProfile\\nProactive B.Sc  Computer Science graduate \\nwith experience in customer service and \\ntechnical support, currently pursuing an MBA \\nin Business Analytics. Skilled in partner \\nonboarding, issue resolution, and relationship \\nmanagement with strong communication and \\nanalytical abilities. Adept at troubleshooting \\ntechnical issues, updating knowledge bases, \\nand ensuring partner satisfaction through \\ntimely support and effective coordination \\nwith internal teams.\\nSkills\\nTechnical Skills\\n•Python\\n•DBMS\\n•SQL\\n•Data Analysis & Visualization\\n•Technical Troubleshooting & Issue \\nResolution\\nBusiness & Domain Skills\\n•Banking Operations & Compliance\\n•Customer Data Management & Risk \\nAnalysis\\n•Business Process Improvement\\nSoft Skills\\n•Analytical Thinking & Problem Solving\\n•Strong Communication & Presentation\\n•Team Collaboration and Management\\nDeclaration\\nDeclaration I hereby declare that the\\ninformation provided above is true and correct\\nto the best of my knowledge and belief.\\nProfessional Experience\\nThe Federal Bank Limited\\nCustomer Service Associate\\n08/2023 – 08/2025\\n•Managed customer interactions, resolved \\nqueries, and ensured compliance with \\nbanking regulations, enhancing customer \\nsatisfaction.\\n•Gained deep understanding of banking \\noperations, cash handling, KYC, loan \\nprocessing, and customer data management.\\n•Collaborated with the analytics team to \\nprovide operational insights and support \\ndata accuracy for reporting purposes.\\n•Assisted in process improvement initiatives \\nby analyzing transaction data trends and \\nidentifying bottlenecks.\\nLanguages\\nEnglish, Tamil, Baduga\\nCourses\\nMBA in Business Analytics\\nAmrita School of Business (ASB).\\n08/2025 – Present | COIMBATORE\\nCertificates\\nCertified in Multimedia and Animation.\\nCyber Security\\nAutoDesk Principal of Design Thinking')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc=[]\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        loader=PyPDFLoader(os.path.join(folder_path+\"\\\\\"+file))\n",
    "        doc= loader.load()\n",
    "        all_doc.extend(doc)\n",
    "all_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de0084ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6823ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted into  15 chunks\n"
     ]
    }
   ],
   "source": [
    "splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=10)\n",
    "chunk=splitter.split_documents(all_doc)\n",
    "print(\"splitted into \",len(chunk),\"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15bf1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7f1c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding= HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19bc57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2dc27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=FAISS.from_documents(chunk,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72fcda6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded  15 chunk to vector db\n"
     ]
    }
   ],
   "source": [
    "print(\"uploaded \",db.index.ntotal,\"chunk to vector db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b42d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e32e09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_14564\\1555928118.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b7e53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve= db.as_retriever(search_kwargs={'k':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7a42efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42f39c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"Give response only from the below details\n",
    "{context}\n",
    "question : {question}\n",
    "\"\"\"\n",
    "prompt=ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0df3cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b9d2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain=(\n",
    "    {'context': retrieve | (lambda docs : \"\\n\".join( doc.page_content for doc in docs)),'question' : RunnablePassthrough()}\n",
    "    |prompt\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b696dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['list the projects done in meta and teksystems',\n",
    "           'list the skillset of nivash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07060583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt : list the projects done in meta and teksystems\n",
      "Response : Here are the projects mentioned:\n",
      "\n",
      "1. LLM Data Pipeline & Annotation Analytics (Meta) - November 2023 to July 2025:\n",
      "   * Improved data quality and annotation workflows for Generative AI projects.\n",
      "   * Assisted in process improvement initiatives by analyzing transaction data trends and identifying bottlenecks.\n",
      "\n",
      "2. Recommendation Updates (POC Project) - Refined AI-generated recommendations using iterative prompt strategies, enhancing accuracy and real-time adaptability for users.\n",
      "\n",
      "3. Dialogue Flow & Intent Optimization – Internal CX Project (POC Project) - Improved chatbot performance by analyzing and creating intents, reducing fallback responses, and enhancing query accuracy.\n",
      "\n",
      "Note that the \"LLM Data Pipeline & Annotation Analytics\" project was done at Meta and the other two projects were part of POC projects at Meta.\n",
      "Prompt : list the skillset of nivash\n",
      "Response : Here is the list of skills for NIVASH R:\n",
      "\n",
      "**Technical Skills:**\n",
      "\n",
      "1. Python\n",
      "2. DBMS\n",
      "3. SQL\n",
      "4. Data Analysis & Visualization\n",
      "5. Technical Troubleshooting & Issue Resolution\n",
      "\n",
      "**Business & Domain Skills:**\n",
      "\n",
      "1. Banking Operations & Compliance\n",
      "2. Customer Data Management & Risk Analysis\n",
      "3. Business Process Improvement\n",
      "\n",
      "**Soft Skills:**\n",
      "\n",
      "1. Analytical Thinking & Problem Solving\n",
      "2. Strong Communication & Presentation\n",
      "3. Team Collaboration and Management\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    print(f\"Prompt : {q}\")\n",
    "    answer=rag_chain.invoke(q)\n",
    "    print(f\"Response : {answer}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b3287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b70818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c4094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
