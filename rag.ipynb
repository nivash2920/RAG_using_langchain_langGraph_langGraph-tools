{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc313cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26765cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Asus\\\\Desktop\\\\all projects & learnings\\\\llm-rag-fastapi-study'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path=os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d55a2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=\"C:\\\\Users\\\\Asus\\\\Documents\\\\all_doc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1713e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13d7189c",
   "metadata": {},

     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc=[]\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        loader=PyPDFLoader(os.path.join(folder_path+\"\\\\\"+file))\n",
    "        doc= loader.load()\n",
    "        all_doc.extend(doc)\n",
    "all_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de0084ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6823ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted into  15 chunks\n"
     ]
    }
   ],
   "source": [
    "splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=10)\n",
    "chunk=splitter.split_documents(all_doc)\n",
    "print(\"splitted into \",len(chunk),\"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15bf1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7f1c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding= HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19bc57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2dc27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=FAISS.from_documents(chunk,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72fcda6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded  15 chunk to vector db\n"
     ]
    }
   ],
   "source": [
    "print(\"uploaded \",db.index.ntotal,\"chunk to vector db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b42d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e32e09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_14564\\1555928118.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b7e53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve= db.as_retriever(search_kwargs={'k':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7a42efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42f39c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"Give response only from the below details\n",
    "{context}\n",
    "question : {question}\n",
    "\"\"\"\n",
    "prompt=ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0df3cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b9d2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain=(\n",
    "    {'context': retrieve | (lambda docs : \"\\n\".join( doc.page_content for doc in docs)),'question' : RunnablePassthrough()}\n",
    "    |prompt\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b696dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['list the projects done in meta and teksystems',\n",
    "           'list the skillset of nivash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07060583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt : list the projects done in meta and teksystems\n",
      "Response : Here are the projects mentioned:\n",
      "\n",
      "1. LLM Data Pipeline & Annotation Analytics (Meta) - November 2023 to July 2025:\n",
      "   * Improved data quality and annotation workflows for Generative AI projects.\n",
      "   * Assisted in process improvement initiatives by analyzing transaction data trends and identifying bottlenecks.\n",
      "\n",
      "2. Recommendation Updates (POC Project) - Refined AI-generated recommendations using iterative prompt strategies, enhancing accuracy and real-time adaptability for users.\n",
      "\n",
      "3. Dialogue Flow & Intent Optimization â€“ Internal CX Project (POC Project) - Improved chatbot performance by analyzing and creating intents, reducing fallback responses, and enhancing query accuracy.\n",
      "\n",
      "Note that the \"LLM Data Pipeline & Annotation Analytics\" project was done at Meta and the other two projects were part of POC projects at Meta.\n",
      "Prompt : list the skillset of nivash\n",
      "Response : Here is the list of skills for NIVASH R:\n",
      "\n",
      "**Technical Skills:**\n",
      "\n",
      "1. Python\n",
      "2. DBMS\n",
      "3. SQL\n",
      "4. Data Analysis & Visualization\n",
      "5. Technical Troubleshooting & Issue Resolution\n",
      "\n",
      "**Business & Domain Skills:**\n",
      "\n",
      "1. Banking Operations & Compliance\n",
      "2. Customer Data Management & Risk Analysis\n",
      "3. Business Process Improvement\n",
      "\n",
      "**Soft Skills:**\n",
      "\n",
      "1. Analytical Thinking & Problem Solving\n",
      "2. Strong Communication & Presentation\n",
      "3. Team Collaboration and Management\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    print(f\"Prompt : {q}\")\n",
    "    answer=rag_chain.invoke(q)\n",
    "    print(f\"Response : {answer}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b3287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b70818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c4094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
