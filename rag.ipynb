{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc313cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26765cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Asus\\\\Desktop\\\\all projects & learnings\\\\llm-rag-fastapi-study'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path=os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55a2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=\"C:\\\\Users\\\\Asus\\\\Documents\\\\all_doc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1713e48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Desktop\\all projects & learnings\\llm-rag-fastapi-study\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d7189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc=[]\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        loader=PyPDFLoader(os.path.join(folder_path+\"\\\\\"+file))\n",
    "        doc= loader.load()\n",
    "        all_doc.extend(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0084ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6823ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted into  15 chunks\n"
     ]
    }
   ],
   "source": [
    "splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=10)\n",
    "chunk=splitter.split_documents(all_doc)\n",
    "print(\"splitted into \",len(chunk),\"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15bf1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7f1c413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_22624\\3386098630.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding= HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embedding= HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bc57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2dc27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=FAISS.from_documents(chunk,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72fcda6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded  15 chunk to vector db\n"
     ]
    }
   ],
   "source": [
    "print(\"uploaded \",db.index.ntotal,\"chunk to vector db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b42d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e32e09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_22624\\1555928118.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b7e53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve= db.as_retriever(search_kwargs={'k':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a42efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42f39c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"Give response only from the below details\n",
    "{context}\n",
    "question : {question}\n",
    "\"\"\"\n",
    "prompt=ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0df3cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b9d2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain=(\n",
    "    {'context': retrieve | (lambda docs : \"\\n\".join( doc.page_content for doc in docs)),'question' : RunnablePassthrough()}\n",
    "    |prompt\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b696dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['list the projects done in meta and teksystems',\n",
    "           'list the skillset of nivash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07060583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt : list the projects done in meta and teksystems\n",
      "Response : Here are the projects mentioned:\n",
      "\n",
      "1. LLM Data Pipeline & Annotation Analytics (Meta) - November 2023 to July 2025\n",
      "2. Recommendation Updates (POC Project) - Refined AI-generated recommendations using iterative prompt strategies, enhancing accuracy and real-time adaptability for users.\n",
      "3. Dialogue Flow & Intent Optimization â€“ Internal CX Project (POC Project) - Improved chatbot performance by analyzing and creating intents, reducing fallback responses, and enhancing query accuracy.\n",
      "\n",
      "For Teksystems:\n",
      "No specific projects are mentioned in the given details.\n",
      "Prompt : list the skillset of nivash\n",
      "Response : Here are the skills listed for Nivash:\n",
      "\n",
      "1. Technical Skills:\n",
      "   - Python\n",
      "   - DBMS\n",
      "   - SQL\n",
      "   - Data Analysis & Visualization\n",
      "   - Technical Troubleshooting & Issue Resolution\n",
      "\n",
      "2. Business & Domain Skills:\n",
      "   - Banking Operations & Compliance\n",
      "   - Customer Data Management & Risk Analysis\n",
      "   - Business Process Improvement\n",
      "\n",
      "3. Soft Skills:\n",
      "   - Analytical Thinking & Problem Solving\n",
      "   - Strong Communication & Presentation\n",
      "   - Team Collaboration and Management\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    print(f\"Prompt : {q}\")\n",
    "    answer=rag_chain.invoke(q)\n",
    "    print(f\"Response : {answer}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b3287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b70818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c4094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
